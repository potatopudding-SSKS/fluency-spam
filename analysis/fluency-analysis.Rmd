---
title: "VFT/SpAM data processing"
output: html_document
date: "2025-07-10"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Import Libraries
```{r}
library(tidyverse)
library(jsonlite)
```

# Importing Data
```{r}
#Pilot participant csv data file:
datafile <- read_csv("../data/fluency_193.csv")

#Viewing the data file in seperate tab:
View(datafile)
```

# Cleaning Data
```{r}
#checking if each subject completed each domain,
# only keeping data from those who completed all domains

n_domains = 1 # CHANGE BASED ON STUDY
key_domains = c("animals") # CHANGE BASED ON STUDY
good_domain_counts <- datafile %>%
    filter(task == "VFT"& domain %in% key_domains) %>% 
  group_by(subject,run_id) %>%
  summarise(unique_domains = n_distinct(domain))%>%
  filter(unique_domains==n_domains) 
```

# Cleaning Fluency Data 
```{r}
safe_fromJSON <- function(x) {
  tryCatch(fromJSON(x), error = function(e) NULL)
}
#to make data analysis through Forager easier:
organized_fluency <- datafile %>% #initiates dplyr pipeline
  filter(
    task == "VFT", domain %in% key_domains,
   !is.na(tagged_responses),
   !is.na(response_times)
    ) %>% 
  mutate(
    parsed_responses = map(tagged_responses, safe_fromJSON),
    parsed_times = map(response_times, safe_fromJSON)
  ) %>%
  filter(
    !map_lgl(parsed_responses, is.null),
    !map_lgl(parsed_times, is.null)
  ) %>%
  unnest_longer(parsed_responses, indices_to = "idx") %>%
  unnest_longer(parsed_times, indices_to = "idx_time") %>%
  filter(idx == idx_time) %>%
  unnest_wider(parsed_responses, names_sep = "_") %>%
  transmute(
    subject,
    response = parsed_responses_response,
    entry_number = parsed_responses_tag,
    response_times = parsed_times,
    domain
    ) %>%
  arrange(subject, domain, entry_number)

#write_csv(organized_fluency, "../Data/Pilot Data/organized_fluency.csv") 
View(organized_fluency)

## NOTE: THIS FILE WILL THEN BE PLUGGED INTO THE FORAGER PIPELINE
## ONCE WE HAVE THE SEMANTIC EMBEDDINGS AND PHONETIC TRANSCRIPTIONS FOR ALL WORDS

```

# Cleaning SpAM Data
```{r}
organized_spam <- datafile %>%
  filter(
    #subject %in% good_domain_counts$subject,
    task == "SpAM",
    !is.na(droppedwords),
    droppedwords != "[]",
    droppedwords != "",
    domain %in% key_domains
  ) %>%
  rowwise() %>%
  mutate(droppedwords = list(fromJSON(droppedwords))) %>%
  filter(length(droppedwords) > 0) %>%
  unnest_longer(droppedwords) %>%
  unnest_wider(droppedwords) %>%
  ungroup() %>%
  group_by(subject, domain, id) %>%
  slice_tail(n = 1) %>%                     # keep only most recent position per id
  ungroup() %>%
  mutate(entry_number = as.numeric(str_remove(id, "word-"))) %>%
  arrange(subject, domain, entry_number) %>%
  group_by(domain, subject) %>%
  mutate(
    x_next = lead(x_norm),
    y_next = lead(y_norm),
    euclidean_distance = sqrt((x_next - x_norm)^2 + (y_next - y_norm)^2))%>%
  mutate(euclidean_distance = lag(euclidean_distance))%>%
  ungroup()%>%
  select(-x_next, -y_next)

View(organized_spam)
# write_csv(organized_spam, "../Data/Pilot Data/organized_spam.csv")
```

#  Cleaning demographics data

Might need to be cleaned up a bit more once we have finalized our questions.
```{r}
cols_to_select <- c("run_id", "age", "gender", "education", "question_order", "race", "hispanic", "dominant_hand", "alert_time", "english", "additional_languages")

optional_cols <- c("first_language", "age_learned_english")
cols_to_select <- c(cols_to_select, optional_cols[optional_cols %in% colnames(datafile)])

demographics_cleaned <- datafile %>%
  filter(typeoftrial == "demographics",
         run_id %in% good_domain_counts$run_id
         ) %>%
  select(all_of(cols_to_select)) %>%
  filter(!if_all(everything(), is.na)) %>%
  mutate(
    age = as.numeric(age),
    education = as.numeric(education),
    gender = as.character(gender),
    english = as.character(english),
    additional_languages = as.character(additional_languages),
    across(any_of(c("first_language", "age_learned_english")), as.character)
  ) %>%
  mutate(across(c(age, gender, education, race, hispanic, dominant_hand, alert_time, english),
                ~ifelse(. == "" | is.na(.), "blank", .))) %>%
  mutate(gender = case_when(
    gender %in% c("Cis-female", "Female", "F") ~ "F",
    gender %in% c("cis male", "i am a boy", "M") ~ "M",
    gender == "blank" | is.na(gender) ~ "blank",
    TRUE ~ as.character(gender)
  )) %>%
  mutate(Gender_Abbrev = str_to_upper(str_sub(gender, 1, 1)),
         Gender_Abbrev = case_when(
           Gender_Abbrev == "W" ~ "F",
           Gender_Abbrev %in% c("T", "N") ~ "N",
           TRUE ~ Gender_Abbrev
         )) %>%
  group_by(run_id) %>%
  fill(everything(), .direction = "downup") %>%
  slice(1) %>%
  ungroup()

write_csv(demographics_data, "../Data/Pilot Data/demographics_data.csv")
View(demographics_data)
```
